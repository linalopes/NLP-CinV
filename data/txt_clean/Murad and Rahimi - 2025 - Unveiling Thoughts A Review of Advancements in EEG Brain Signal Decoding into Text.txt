Unveiling Thoughts: A Review of Advancements in EEG Brain Signal Decoding into Text

Saydul Akbar Murad , 1 (IEEE Member) Nick Rahimi , 1 (IEEE Member)

Abstract -The conversion of brain activity into text using electroencephalography (EEG) has gained significant traction in recent years. Many researchers are working to develop new models to decode EEG signals into text form. Although this area has shown promising developments, it still faces numerous challenges that necessitate further improvement. It's important to outline this area's recent developments and future research directions. In this review article, we thoroughly summarize the progress in EEG-to-text conversion. Firstly, we talk about how EEG-to-text technology has grown and what problems we still face. Secondly, we discuss existing techniques used in this field. This includes methods for collecting EEG data, the steps to process these signals, and the development of systems capable of translating these signals into coherent text. We conclude with potential future research directions, emphasizing the need for enhanced accuracy, reduced system constraints, and the exploration of novel applications across varied sectors. By addressing these aspects, this review aims to contribute to developing more accessible and effective Brain-Computer Interface (BCI) technology for a broader user base.

Secondly, the potential applications of this technology are vast, particularly in the realm of communication assistance [3]. Finally, the non-invasive nature of EEG makes it a promising option for individuals who are unable to employ conventional modes of communication. For individuals with conditions like amyotrophic lateral sclerosis (ALS), stroke, or severe cerebral palsy, traditional communication methods can be severely limited or even impossible [1]. Brain-to-text communication presents a promising prospect, as it gives a direct means for individuals to articulate their thoughts and requirements [4]. This technology has the potential to revolutionize their lives, enabling them to interact with the world, express themselves creatively, and regain a sense of independence.

Index Terms -EEG, Neuroscience, Signal Decoding, Deep Learning, BCI.

I. INTRODUCTION

EEG-based brain-to-text communication is a revolutionary field that explores using EEG to decode brain signals into actual text. EEG measures electrical activity on the scalp, and researchers are currently devising techniques to convert particular patterns into letters, words, and even sentences. This technological advancement exhibits significant promise for persons who experience speech or motor disabilities, offering a direct communication channel that bypasses traditional methods. BCIs play a pivotal role in EEG-based brain-to-text communication. BCIs bridge the gap between the brain and external devices by interpreting brain signals to facilitate control or communication. They have evolved significantly, from early systems focusing on simple commands to more advanced interfaces capable of recognizing complex thought patterns. This evolution is important for brain-to-text communication, as researchers rely on BCIs to translate the intricate neural correlates of language into meaningful text.

In recent years, there has been a significant increase in research focused on decoding EEG signals for the purpose of direct brain-to-text communication [1]. The increasing interest can be attributed to various things. Firstly, the progress in machine learning algorithms facilitated the researchers to analyze complex EEG patterns with greater accuracy [2].

- 1 School of Computing Sciences &amp; Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, USA. (e-mail: saydulakbar.murad@usm.edu, nick.rahimi@usm.edu)

Early research in EEG primarily concentrated on areas like emotion recognition and neurological condition studies. For instance, in [5], researchers reviewed how EEG signals could be linked to understanding human emotions by analyzing brain activities. A Similar study [6] extended this focus to emotion recognition from EEG data, exploring a range of techniques from initiating emotions through the preprocessing of EEG signals to extracting and classifying features. This research also critically evaluated the strengths and weaknesses of these varied methods. Moving away from emotional analysis, the study [7] shifted the focus toward diagnosing Alzheimer's Disease. It offered an in-depth look into the use of EEG for detecting Alzheimer's, including a detailed analysis of the complexity found in the EEG signals associated with the disease. However, there's still a gap in the literature: no review articles have yet focused on converting EEG signals to text. This gap is significant, considering the potential applications and advancements this research could bring.

Considering the significance of EEG-to-text conversion, this review compiles and examines recent research in this burgeoning field. We aim to outline and discuss the techniques used in transforming EEG signals into text, aiming to guide future research directions. The contributions of our review are the following:

- · Firstly, we address the various challenges faced in decoding EEG signals, providing insight into the complexities inherent in this process.
- · Secondly, we design a comprehensive taxonomy that categorizes and discusses the range of techniques used in this domain, from initial data collection to the intricacies of model development.
- · Lastly, we explore potential avenues for future research, identifying gaps in current knowledge and proposing areas that hold promise for further investigation.

This review aims not just to go over what's been done but also to spark new ideas and paths in the field of EEG-to-text conversion.

The rest of this paper is structured as follows: In Section II, we delve into the challenges of EEG signal decoding, detailing six distinct types of challenges encountered in this field. Section III presents a taxonomy, concentrating on the techniques employed, from the initial stages of data collection to the intricacies of model development. In Section IV, we highlight potential directions for future research. The paper concludes with Section V, summarizing our findings and final thoughts.

II. CHALLENGES IN EEG DECODING

Despite the immense potential of EEG decoding for text generation, translating brain activity into written language presents significant challenges. This section delves into the complexities of this process, highlighting the key hurdles researchers face at each stage. Figure 1 presents the challenges of decoding the EEG signals into text. This figure provides a roadmap to understanding the complexities of EEG decoding for text generation. It outlines the various stages involved, from data acquisition to model building, and highlights the key challenges encountered at each step.

A. Data Acquisition

Signal Acquisition and Quality: Acquiring clean and highquality EEG signals is essential for accurate text decoding. However, this process faces several hurdles. The inherent weakness of brain signals compared to background electrical noise, particularly from muscles and power lines, necessitates sophisticated noise reduction techniques [8], [9]. Furthermore, significant variability in brain activity patterns between individuals due to anatomical and cognitive differences poses a challenge for developing generalized decoding models that work effectively for everyone [10]. Even slight head movements can introduce artifacts, further muddying the signal [8]. Additionally, the limited spatial resolution of EEG, which measures activity from a large brain area, makes it difficult to pinpoint the exact source of language-related activity [11]. Finally, user comfort and training can be hurdles. Wearing an EEG cap with multiple electrodes can be uncomfortable for some users, and extensive training sessions may be required to learn how to control their brain activity for optimal decoding results [12].

Inter-subject Variability: Despite the potential of EEG for text decoding, a major hurdle lies in inter-subject variability. Unlike fingerprints, brain activity patterns are highly individualistic. This variation arises from several sources. Firstly, anatomical differences in brain structure and neuron distribution between people lead to diverse electrical activity patterns [12]. Secondly, cognitive styles influence which brain regions are activated during thought processes. Some individuals may rely heavily on visual processing, while others favor auditory or kinesthetic pathways [10]. Finally, even slight variations in how EEG electrodes are placed on the scalp can significantly impact the recorded signals and decoding accuracy across users [13]. As a result, decoding models may need to be personalized for each user, as a model trained on one person's EEG data might not perform well for someone with a different brain or cognitive style.

B. Data Preprocessing and Feature Selection

Non-Stationary Nature of EEG Signals: Understanding the intricate connection between brain activity and written language is further complicated by the non-stationary nature of EEG signals. Unlike stationary signals with consistent statistical properties over time, EEG signals exhibit dynamic changes [8]. These variances can arise from internal cognitive changes as users direct their attention towards different elements of the text they intend to produce [14]. Additionally, external factors like fatigue or slight head movements might cause temporary fluctuations in the signal [12]. This non-stationary nature poses challenges for data preprocessing and feature selection. Traditional techniques assuming stationary signals may not effectively capture the time-varying information crucial for accurate text decoding. Researchers are exploring methods like time-frequency analysis and adaptive filtering techniques to account for the non-stationary characteristics of EEG signals and extract the most relevant features for successfully decoding brain activity into text [15].

Identifying Informative Features: In the context of transforming EEG data to text, an important step in data preprocessing and feature selection involves identifying informative features. This process is important because EEG data is characteristically high-dimensional and contains a significant amount of non-informative or redundant information. Efficient feature selection can significantly improve the performance of machine learning models used in this domain. The challenge lies in distinguishing relevant features that are most representative of the underlying cognitive or neural processes from the irrelevant ones. Techniques such as PCA, ICA, and mutual information-based methods have been employed to address this issue [16], [17]. These methods aim to reduce the dimensionality of EEG data while retaining the most significant information, facilitating the subsequent machine learning tasks such as classification or regression required for converting EEG signals into text representations. This step is important for applications in BCI, where the goal is to translate neural activity into actionable commands or textual forms [18].

C. Model Building and Decoding

Limited training data: The scarcity of training data poses a major obstacle in the creation of efficient EEG-to-text algorithms. Due to the inherent complexity and variability of EEG signals, coupled with the difficulty in collecting large datasets, machine learning models often suffer from inadequate training, leading to poor generalization and performance. This problem is most noticeable in EEG-to-text applications, where the model needs to interpret intricate brain signals and produce accurate textual results. Transfer learning and data augmentation are often used techniques to address this difficulty. Transfer learning involves fine-tuning a pre-trained model on a smaller dataset, while data augmentation artificially

Figure 1: Challenges in EEG Signal Decoding for Text Generation.

enhances the quantity and variability of training datasets [19]. Furthermore, the use of generative models to create synthetic EEG data, which resembles real recordings, has shown promise in enhancing the training process (Hartmann et al., 2018). These approaches aim to overcome the limitations imposed by scarce EEG data, thus improving the accuracy and reliability of EEG-to-text conversion models crucial for applications in neural prosthesis and BCI [20].

Accuracy and Fluency: Attaining a high level of accuracy and fluency is still a difficult task when it comes to constructing models and decoding for EEG-to-text conversion. The inherent complexity of interpreting EEG signals, which are often noisy and highly individualized, poses significant difficulties in accurately translating these signals into coherent and fluent text. The accuracy of a model refers to its ability to accurately interpret the EEG signals, while fluency pertains to the naturalness and readability of the generated text. These dual objectives often require sophisticated algorithms that can handle the intricate patterns in EEG data. Researchers have studied the possibility of deep learning models, specifically recurrent neural networks (RNNs) and attention mechanisms, to improve both accuracy and fluency in this field [21]. These models can capture temporal dependencies and contextual nuances in the EEG signals, which are crucial for producing precise and fluent text output. However, the trade-off between accuracy and fluency remains a key area of research, as improving one aspect can sometimes be at the expense of the other. This balancing act is critical in applications like real-time communication aids for individuals with speech impairments, where both accuracy and fluency are essential for effective interaction [22], [23].

directly affect the quality and resolution of EEG signals, which are essential for proper decoding. The availability of highresolution EEG devices, which offer intricate neurological data, is often restricted due to their high cost and limited accessibility. Consequently, the general utilization of advanced EEG-to-text applications is hindered [24]. Moreover, these sophisticated devices can be unwieldy and intrusive, impeding their suitability for daily usage. However, portable and userfriendly EEG equipment typically have lower resolution and are more prone to noise and aberrations. These factors can have a negative impact on the performance of EEG-to-text models [25]. The difficulty is in achieving a harmonious equilibrium between the excellence of EEG data capture and the feasibility and availability of the technology. In addition, the processing and decoding of EEG data in real-time necessitate high-performance processing units, which may not be practical for portable or wearable devices [26], [27]. The hardware limitation plays a crucial role in assessing the practicality and efficiency of EEG-to-text systems, especially in the context of assistive communication devices designed for individuals with speech or mobility disabilities.

D. System Limitations

Hardware Constraints: Hardware limitations pose a substantial obstacle in the creation and execution of EEG-to-text systems. The capabilities of the EEG recording equipment

Calibration Time: Calibration time poses a substantial challenge in developing and implementing EEG-to-text models. Calibrating EEG devices to individual users is essential for accurately decoding neural signals. However, this process can be time-consuming and demands substantial human exertion. The brainwave patterns of each individual are distinct, and the EEG system must be precisely calibrated to these patterns to achieve successful communication or control. The calibration process often requires the user to engage in specific cognitive tasks regularly, enabling the system to learn and adjust to their EEG signals [27], [28]. The calibration process for EEG-to-text systems might be challenging in terms of time and effort, especially when considering their applicability to individuals with disabilities or in time-critical scenarios. Efforts to decrease the time required for calibration while also

upholding or enhancing the precision and dependability of the system are a crucial focus of research. Researchers are currently investigating emerging methods, such as adaptive algorithms and transfer learning, to tackle this difficulty. These methods involve using calibration data from one user to help calibrate the system for another user [26], [29]. The objective of these techniques is to enhance the user-friendliness and accessibility of EEG-to-text systems, hence expanding their range of potential applications.

E. User Related Challenges

Mental Focus: The use of EEG-to-text systems faces a notable user-related barrier in terms of mental attention. The success of these systems heavily depends on the user's capacity to sustain unwavering mental concentration, as fluctuations in attention can result in significant deviations in EEG signal patterns, thus impacting the precision of signal interpretation and text generation. This is particularly challenging because maintaining a high concentration level over extended periods is difficult for most individuals. Fatigue, distraction, and cognitive load can all adversely impact the user's ability to generate stable and clear EEG signals [30]. Moreover, the requirement for sustained mental focus can be especially demanding for users with cognitive or attention impairments, limiting the accessibility and usability of EEG-to-text technologies for these populations. Researchers are exploring various strategies to address this challenge, such as developing more robust algorithms that can cope with fluctuating levels of user attention and integrating adaptive learning systems that adjust to the user's mental state [27]. The purpose of these developments is to improve the robustness of EEG-to-text systems against fluctuations in mental concentration, thus increasing their practicality and efficacy for a wider spectrum of users.

Fatigue and Training: User-related issues in EEG-to-text communication systems include fatigue and the requirement for substantial training. Users often experience fatigue during prolonged use of EEG systems, as the process of generating consistent and accurate neural signals for text communication requires considerable mental effort and concentration. Fatigue can result in a deterioration of the quality of the EEG signals, which in turn affects the function of the system [31]. Furthermore, the requirement for extensive training to use EEG-totext systems efficiently can be a barrier to their widespread adoption, particularly for individuals with disabilities or those who lack the time and resources for lengthy training sessions. The training process involves users learning to generate distinct neural patterns that the system can recognize and translate into text, which can be a time-consuming and demanding task [32]. To address these challenges, researchers are focusing on developing more intuitive and user-friendly interfaces, as well as adaptive algorithms that require less user training and are more resilient to the effects of fatigue [27].

F. Ethical Considerations

Privacy Concerns: Privacy concerns constitute a critical ethical challenge in the realm of EEG-to-text technology. EEG data, which might disclose private and confidential information about a person's mental condition, thoughts, or intentions, presents substantial concerns regarding privacy [33]. Preserving the confidentiality and security of this data is of utmost importance, as breaches could result in unauthorized access and exploitation of personal information. This is particularly relevant in the context of BCIs, where EEG data is used for direct communication or control. The risk of eavesdropping or hacking into these systems poses a serious threat to user privacy [34]. To address these concerns, researchers and developers are exploring various data protection strategies, such as advanced encryption methods and strict access controls, to safeguard against unauthorized data access and ensure compliance with privacy regulations [35]. Furthermore, ethical guidelines and frameworks are being developed to guide the responsible use of EEG data and protect individuals' privacy rights in the use of EEG-to-text and other BCI technologies [36].

Accessibility and Equity: Ensuring accessibility and equity are crucial ethical considerations while developing and using EEG-to-text technology. The potential of these systems to provide communication aids for individuals with disabilities highlights the need for inclusive design and equitable access. Nevertheless, there is a potential danger that these technologies may exacerbate the disparity between individuals who have access to sophisticated medical and assistive technologies and those who do not, owing to factors such as expense, technological proficiency, and the presence of healthcare facilities [37]. Furthermore, the development of EEG-to-text systems frequently prioritizes the preferences of a typical user, possibly neglecting the distinct demands of individuals with different abilities and backgrounds. This lack of inclusivity can result in technologies that are not equally accessible or beneficial to all potential users [38]. Addressing these issues, it is essential to focus on developing EEG-to-text and other BCI technologies using universal design principles. This involves considering the varied requirements and situations of different user groups. Furthermore, policy measures and funding initiatives could play a significant role in ensuring equitable access to these technologies, particularly for underserved and marginalized communities [39].

III. EEG TO GENERATIVE MODEL PIPELINE

Extracting meaningful information from electroencephalogram (EEG) signals is crucial for various applications in neuroscience, brain-computer interfaces, and clinical diagnosis. This process typically involves several stages, as illustrated in Figure 2. The initial stage focuses on data acquisition, where electrodes record EEG signals from the scalp. Subsequently, preprocessing techniques are employed to remove noise and artifacts, ensuring the quality of the data for further analysis. After the EEG signals have been preprocessed, feature extraction is a key step in turning them into useful features that capture the right characteristics for the application. This article delves into various feature extraction techniques commonly employed in EEG signal processing.

Figure 2: Taxonomy of EEG Signal Processing for Text and Image Generation.

A. Data Acquisition

(fMRI) to more invasive methods such as Electrocorticography (ECoG).

The data acquisition process encompasses two key components: the dataset and the device. The dataset aspect involves an examination of existing data previously utilized for converting brain signals into text and images. This part of the process focuses on how this data was initially collected and processed to facilitate the transformation of neural activity into comprehensible formats like text and visual imagery. Conversely, the device segment delves into the various instruments employed to gather data directly from the brain. This includes an array of technologies ranging from non-invasive tools like EEG, Magnetoencephalography (MEG), and Functional MRI

1) Datasets:

a) Generate Text : Many researchers have made significant contributions to the field of brain signal decoding into text, resulting in the publication of various datasets. These datasets have been gathered using both invasive techniques, like ECoG, and non-invasive techniques, including EEG and fMRI. Notably, ZuCo 1.0 [40] and ZuCo 2.0 [41] are prominent EEG-based datasets collected using setups with 128 channels. In contrast, when utilizing fMRI for data collection [42], [43], researchers often employ 32-channel head coils.

Additionally, ECoG, a widely used method for brain signal acquisition [44], [45], typically involves the use of 16 channels during experiments. Table I lists the datasets utilized for decoding human brain signals into text.

b) Generate Image : Many other researchers have focused on creating images from brain signals, primarily utilizing non-invasive methods such as EEG [46]-[48] and fMRI [46], [49]-[51]. In these studies, the stimuli primarily consist of images, though a few studies have also explored the use of text as stimuli. This exploration into brain signal-based image generation is a growing field, delving into the complex relationship between neural activity and visual representation. By analyzing brain responses to visual stimuli, these studies aim to reconstruct or generate images that correlate with the observed brain activity, providing insights into how the brain processes and interprets visual information. Table II provides a comprehensive list of datasets used to convert human brain signals into images.

2) Devices : Various companies offer a variety of devices for monitoring human brain signals, utilizing both invasive and non-invasive methods to collect data. In non-invasive techniques, electrodes are positioned on the scalp without surgical intervention. This approach is commonly used due to its safety and ease of application. In contrast, invasive techniques involve a surgical process to place electrodes directly on or within the brain, providing more direct and often more detailed brain signal readings. Table III provides a comprehensive overview of the most popular devices currently used. This includes various organizations such as NeuroScan [52], Brain Products [53], BioSemi [54], Emotiv [55], NeuroSky [56], ANT Neuro [57], ABM [58], and OpenBCI [59]. Each organization designs devices with varying ranges of electrical channels and frequencies.

B. Data Pre-processing

1) Artifact Removal: During EEG signal collection, artifacts are a common issue. These artifacts can be of two types: psychological and non-psychological. Non-psychological artifacts originate from external sources such as electrode malfunctions, the movement of cables, or poor connections in channels. On the other hand, physiological artifacts are caused by internal electrical signals within the body. It is necessary to remove these unwanted signals. Some physiological artifacts, like those caused by skin and sweat, can be eliminated during neural activity recording. For example, wearing a cooling ventilation vest helps regulate body temperature during physical activities. Power line artifacts can be effectively filtered out using notch filtering techniques. Moreover, movementrelated distortions in the EEG signal, caused by head or body motion and the resultant electrode and cable movement, can be reduced by employing a double-layer cap.

In the field of EEG signal processing, various strategies have been developed to eliminate artifacts, as depicted in Figure 1. These techniques are broadly categorized into two groups: single artifact removal and multiple artifact removal methods. Common single artifact removal methods utilized by researchers include techniques such as Regression (REG) [60],

Blind Source Separation (BSS) [61], Wavelet Transform (WT) [62], [63], Empirical Mode Decomposition (EMD) [64], and Vertical Mode Decomposition (VMD) [65]. In recent times, there has been a growing trend among researchers to combine two single artifact removal methods to enhance the efficacy of artifact removal from EEG signals. This approach has led to the development of sophisticated hybrid techniques such as VMD-BSS [66], BSS-SVM [67], ICA-WT [68], and REGICA [69]. These multiple artifact removal techniques offer a more robust and comprehensive approach, addressing a broader range of artifacts compared to single artifact removal methods. Consequently, they have gained popularity in the research community for their improved ability to clean EEG signals from various types of unwanted interference. Table IV delineates a range of artifact mitigation strategies employed in EEG signal analysis as explored by various researchers.

2) Filtering : Filtering is another important step of EEG signal processing that is used to enhance the quality of the signal by minimizing noise and interference that can obscure the actual signals. There are many ways from which the unwanted signals come, such as power line noise, environmental electromagnetic interference, and physiological artifacts like muscle movements or eye blinks. By removing these unwanted signals, filtering makes it possible to separate the meaningful brainwave patterns that are useful in research. This isolation is particularly important because EEG signals are typically weak and can be easily contaminated by extraneous noise.

EEG signals can be categorized into two primary types: linear and nonlinear. Linear filters, such as low-pass [70], highpass [71], band-pass [72], band-stop [73], and butter-worth filters [74], are commonly used to remove frequency components outside of the desired range. For instance, low-pass filters are employed to filter out high-frequency disturbances, while high-pass filters are designed to eliminate low-frequency noise. Conversely, bandpass filters are adept at removing noise that lies outside a designated frequency band. Nonlinear filters, on the other hand, include adaptive filters [75] and median filters [76], which are more complex and can be tailored to the specific characteristics of the EEG signal. Adaptive filters are particularly useful in scenarios where the signal or noise characteristics are changing over time, as they can dynamically adjust their filtering parameters. The choice of filter type and settings mainly depends on the characteristics of the EEG data and the goals of the analysis. This flexibility and specificity in filtering ensure that the most relevant and accurate information is extracted from the EEG data, significantly enhancing the quality of the signals.

3) Segmentation: Segmentation in EEG signal processing is an important preprocessing step that involves dividing continuous EEG data into smaller, more manageable segments. It's important for many different reasons. Firstly, it enhances noise reduction, as segmenting the signal allows for easier identification and elimination of artifacts and interference [75]. Secondly, it facilitates event-related analysis, particularly in cognitive or sensory studies, by enabling precise examination of brain responses to specific stimuli [77]. Moreover, considering the non-stationary nature of EEG signals, segmentation helps analyze data within shorter, more statistically uniform

Table I: Description of Publicly Available Datasets Used for Text Generation

| Datasets        | Participants   | Participants   | Participants   | Participants   | Channels                                      | Stimulus                    |
|-----------------|----------------|----------------|----------------|----------------|-----------------------------------------------|-----------------------------|
|                 | Male           | Female         | Total          | Age            | Channels                                      |                             |
| ZuCo 1.0 [40]   | 7              | 5              | 12             | 22-54          | EEG (128)                                     | 1107 English sentences      |
| ZuCo 2.0 [41]   | 9              | 10             | 19             | 23-54          | EEG (128)                                     | 739 English sentences       |
| fMRI Image [42] | -              | -              | 5              | 21-50          | 32-channel head coil                          | 15 subjects with 540 scans  |
| fMRI Image [43] | -              | -              | -              | -              | fMRI                                          | 180 fMRI Images             |
| ECoG Data [44]  | -              | -              | 7              | -              | Eight16-channel g.USBamp biosignal amplifiers | 4381 second voice recording |
| ECoG Data [45]  | 1              | 4              | 5              | 29-49          | 16 Channel                                    | 4053 English sentences      |

Table II: Description of Publicly Available Datasets Used for Image Generation

| Datasets        | Participants   | Participants   | Participants   | Participants   |                                                   | Stimulus                     |
|-----------------|----------------|----------------|----------------|----------------|---------------------------------------------------|------------------------------|
|                 | Male           | Female         | Total          | Age            | Channels                                          |                              |
| EEG + fMRI [46] | -              | -              | 5              | 25-27          | EEG(64), 3.0-Tesla Siemens MAGNETOM Verio scanner | 50 images in 20 category     |
| EEG data [47]   | -              | -              | 23             | 15-40          | EEG (14)                                          | 20 text and10 non-text items |
| EEG data [48]   | 5              | 1              | 6              | -              | EEG (128)                                         | 2000 image                   |
| fMRI [49]       | 2              | 1              | 3              | 23-33          | 3.0-Tesla Siemens MAGNETOM Verio scanner          | 1200 natural images          |
| fMRI [50]       | -              | -              | 2              | -              | 4T INOVAMR scanner                                | 1870 images                  |
| NSD [51]        | -              | -              | 8              | -              | fMRI                                              | 27750 fMRI-image             |

| Name                | Sampling Rate           | Channel          | Devices   | Devices   | Devices   |
|---------------------|-------------------------|------------------|-----------|-----------|-----------|
|                     |                         |                  | EEG       | MEG       | fMRI      |
| NeuroScan [52]      | 500 Hz                  | 32, 64, 128, 256 | ✓         | ✓         | ✓         |
| Brain Products [53] | 1000 Hz, 500 Hz, 250 HZ | 8, 16, 32, 64    | ✓         | ✗         | ✓         |
| BioSemi [54]        | 2048 Hz, 1024 Hz        | 32, 64, 128, 256 | ✓         | ✗         | ✗         |
| Emotiv [55]         | 2048 Hz, 128 Hz         | 2, 5, 14, 32     | ✓         | ✗         | ✗         |
| NeuroSky [56]       | 512 Hz                  | 12               | ✓         | ✗         | ✗         |
| ANT Neuro [57]      | 16 kHz, 2048 Hz         | 32, 64, 128, 256 | ✓         | ✓         | ✓         |
| ABM [58]            | 4 kHz, 2048 Hz          | 24, 32, 64       | ✓         | ✗         | ✗         |
| OpenBCI [59]        | 125 Hz, 200 Hz, 250 Hz  | 4, 8, 16         | ✓         | ✗         | ✗         |

signal itself, thus adapting to the signal's natural structure. Finally, the Sliding Window Transform (SWT) [82] is a complex method that uses wavelet transforms to deal with non-stationary data. It offers a multi-resolution analysis that is useful for pulling out complex EEG signals' nuanced features. Each of these techniques offers distinct advantages and is chosen based on the specific requirements of the study.

intervals, ensuring more accurate interpretations. Finally, from a practical standpoint, segmentation increases computational efficiency by breaking down lengthy EEG recordings into smaller, more computationally manageable units. This preprocessing step is particularly important in studies where temporal precision and data quality are paramount, such as in cognitive neuroscience research, clinical diagnostics, and real-time BCI systems.

Researchers employ various segmentation techniques to mitigate noise in EEG signal processing, each with its own unique approach and application. Fixed-Length Segmentation (FLS) [78] is widely used for its simplicity, segmenting the EEG data into equal, predetermined lengths, thus providing a uniform framework for analysis. Event-related Segmentation (ERS) [79] is tailored for cognitive and sensory studies, where it segments the signal based on specific stimuli or events. Adaptive Segmentation (AS) [75] offers flexibility by adjusting the segment length in response to the signal's characteristics, making it ideal for non-stationary data. EnergyBased Segmentation (EBS) [80] relies on the signal's energy content to determine segment boundaries, which is particularly useful in detecting and analyzing high-energy neural events. Data-Driven Segmentation (DDS) [81] employs algorithms to segment the data based on inherent features of the EEG

4) Normalization : Normalization is another important step in EEG signal processing, mainly due to the high variability of EEG signals both within and between individuals. Normalization helps to mitigate inherent noise in EEG data, such as electrical interference or artifacts from muscle movements, by scaling the EEG signals. EEG signals ensure that outliers or variations in amplitude do not dominate the signal; normalization facilitates the extraction of meaningful biomarkers from the EEG data, which are vital for subsequent analysis and interpretation.

Researchers employ various techniques to normalize EEG signals, each with its own distinct approach to standardizing the data. Min-Max [83] normalization rescales the data to a fixed range, typically [0, 1], ensuring that each signal falls within a standardized band. Z-score [84] normalization, also known as standard score normalization, centers the data around the mean with a unit standard deviation, thereby addressing scale and distribution shape issues. Mean normalization [85] adjusts the data values to revolve around the mean, effectively balancing the dataset around a central value. Decimal normalization [86] shifts the decimal point of values, standardizing them based on their magnitude, which is particularly useful for varying signal amplitudes. Lastly, RMS (Root Mean Square) normalization [87] scales the signal by the square root of the mean squared value, often used to maintain the signal's energy across different conditions. These normalization methods collectively enhance EEG data's comparability and consistency, facilitating more accurate analyses.

C. Feature Extraction

Feature extraction is a critical step in EEG signal processing due to the inherent complexity and high dimensionality of the

Table IV: Comparative Overview of Artifact Removal Techniques in EEG Signal Processing

| Ref.   | Type of Artifact                                                                      | Artifact Removal Technique   | Single Artifact Removal   | Multiple Artifact Removal   | Application Area                                                           | Performance Metrics                                                                         |
|--------|---------------------------------------------------------------------------------------|------------------------------|---------------------------|-----------------------------|----------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|
| [62]   | Motion, Eye blinking, EMG Artifact                                                    | WT                           | ✓                         | ✗                           | Clinical Monitoring                                                        | Signal-to-noise ratio (SNR)                                                                 |
| [63]   | Eye movement and blinking, Swallowing, Chewing, Limb movement, Body movement artifact | WT                           | ✓                         | ✗                           | Brain-Computer Interface (BCI)                                             | Signal-to-noise ratio (SNR), root mean square error (RMSE), Lambda                          |
| [61]   | Ocular, cardiac, muscle and powerline artifacts                                       | BSS                          | ✓                         | ✗                           | Epileptic spike and seizure detection and brain-computer interfaces (BCIs) | Signal-to-artifact ratio (SAR)                                                              |
| [67]   | Eye blinks and heart rhythm artifacts                                                 | BSS - SVM                    | ✗                         | ✓                           | Neurology and brain research                                               | Signal-to-Artifact Ratio (SAR)                                                              |
| [68]   | Electrocardiographic                                                                  | ICA - WT                     | ✗                         | ✓                           | Biomedical engineering                                                     | Signal-to-Artifact Ratio (SAR)                                                              |
| [69]   | Eye movements and blink artifacts                                                     | REG - ICA                    | ✗                         | ✓                           | Biomedical signal processing                                               | Artifact to signal ratio (ASR), Root mean square error (RMSE), Power spectral density (PSD) |
| [60]   | Eye blinking artifacts                                                                | REG                          | ✓                         | ✗                           | Clinical Neurology                                                         | Root Mean Square Error (RMSE), Mutual Information (MI)                                      |
| [64]   | Muscle artifacts                                                                      | EMD                          | ✓                         | ✗                           | Patients with movement disorders                                           | Relative Root Mean Square Error (RRMSE)                                                     |
| [65]   | Eye blinking, flutters and lateral eye movements artifacts                            | VMD                          | ✓                         | ✗                           | Neurophysiology and clinical neurology                                     | Multiscale modified sample entropy (mMSE)                                                   |
| [66]   | Muscular activity, heartbeat, and eye movements                                       | VMD - BSS                    | ✗                         | ✓                           | N/A                                                                        | Euclidean Distance (ED), Spearman Correlation Coefficient (SCC)                             |

Table V: Comparison of Feature Extraction Methods for EEG Signal Processing.

| Ref.   | Time Domain   | Frequency Domain   | Time Frequency Domain   | NLDF   | ITF   | CF   |
|--------|---------------|--------------------|-------------------------|--------|-------|------|
| [88]   | ✓             | ✓                  | ✓                       | ✗      | ✗     | ✗    |
| [89]   | ✗             | ✗                  | ✓                       | ✗      | ✗     | ✗    |
| [90]   | ✗             | ✓                  | ✓                       | ✗      | ✗     | ✗    |
| [91]   | ✗             | ✓                  | ✗                       | ✗      | ✗     | ✗    |
| [92]   | ✗             | ✗                  | ✗                       | ✗      | ✗     | ✓    |
| [93]   | ✗             | ✗                  | ✗                       | ✗      | ✓     | ✗    |
| [94]   | ✗             | ✗                  | ✗                       | ✗      | ✗     | ✓    |
| [95]   | ✗             | ✗                  | ✗                       | ✓      | ✗     | ✗    |
| [96]   | ✓             | ✗                  | ✗                       | ✗      | ✗     | ✗    |
| [97]   | ✗             | ✓                  | ✗                       | ✗      | ✗     | ✗    |
| [98]   | ✗             | ✗                  | ✓                       | ✗      | ✗     | ✗    |

2) Frequency Domain : The frequency domain approach is another highly effective technique for feature extraction in EEG signal processing. This method transforms EEG signals to analyze their frequency components, providing a different perspective compared to time-domain analysis. This domain proves valuable for understanding the dominant rhythms associated with various brain activities and identifying eventrelated changes in the frequency spectrum. Key methods utilized in this domain include Power Spectral Density [97], Band Power [103], Spectral Edge Frequency [104], Common Spatial Pattern [105], and the Auto-regressive Method [106]. Each of these plays a significant role in analyzing and interpreting the complex frequency-based characteristics of EEG data.

data. It acts as a bridge between raw EEG recordings and meaningful insights. Extracting relevant and informative features from various domains (time, frequency, time-frequency, and space) compresses the data while preserving key information crucial for subsequent analysis and interpretation. This allows researchers to effectively utilize ML algorithms and unlock the hidden potential of EEG data for various applications in neuroscience, BCI, and clinical diagnosis. Figure V shows a comparison of different feature extraction methods that were used in previous research.

1) Time Domain : Time-domain analysis is a fundamental approach for extracting features from EEG signals. It focuses on characterizing the signal's behavior directly over time, offering insights into its amplitude, variability, and rhythmicity. This domain proves valuable for capturing transient events and quantifying specific characteristics within the signal. Common time domain techniques include Amplitude measures [96], Statistical measures [99], Hjorth parameters [100], [101], Event-related potentials (ERPs) [102], and Higher-order crossing (HOC) [101]. Each method contributes uniquely to the comprehensive analysis of EEG signals, making them indispensable in extracting meaningful information from complex brain activity.

3) Time Frequency Domain : While both time-domain and frequency-domain analyses offer valuable insights into EEG signals, they each provide a limited perspective. Time-domain analysis excels at capturing temporal dynamics but lacks resolution in the frequency domain. Conversely, frequencydomain analysis excels at revealing spectral characteristics but fails to capture how these characteristics change over time.

To overcome these limitations, researchers often employ time-frequency domain analysis. This approach provides a comprehensive understanding of EEG signals by simultaneously analyzing their temporal and spectral information. By decomposing the signal into its time-frequency components, researchers can gain insights into how the frequency content of the signal evolves over time. Among the most prominent techniques in this domain are the Wavelet Transform [62], [63], Short-Time Fourier Transform (STFT) [ ? ], and HilbertHuang Spectrum [98].

4) Non-linear Dynamic Features (NLDF) : NLDF is a new way to look at EEG signals beyond the usual timedomain, frequency-domain, and time-frequency methods. This method explores the inherent non-linearity and complexity of brain activity, which linear models are unable to capture fully. NLDF techniques focus on extracting features that characterize the dynamic behavior of the EEG signal over time. These

features often involve measures of complexity, chaos, and synchronization, providing insights into the underlying mechanisms of brain function. NLDF such as Lyapunov Exponents [107], Fractal Dimension [95], Correlation Dimension [108], Hurst Exponent [108], Lempel-Ziv Complexity [109], and Recurrence Quantification Analysis [110] are pivotal in EEG signal processing for capturing the complex, dynamic behavior of the brain's electrical activity.

5) Information Theoretic Features (ITF) : In recent years, ITF has emerged as a powerful tool for extracting meaningful information from EEG signals. Entropy [93], a fundamental ITF measure, evaluates the unpredictability or randomness of the signal, offering insights into the complexity of neural dynamics. It is particularly useful in assessing the regularity and predictability of EEG signals, which can be pivotal in differentiating between different neurological states or conditions. On the other hand, Mutual Information [111] measures the amount of information shared between two signals, reflecting the degree of statistical dependency and potential interaction between different brain regions.

6) Connectivity Features (CF) : Beyond analyzing individual brain regions, CF offers a powerful tool for understanding the interplay between different brain areas in EEG signal processing. These features aim to quantify the functional relationships and synchronization patterns between various regions, providing valuable insights into the coordinated activity underlying cognitive processes and brain function. Coherence [92] is a widely utilized CF technique that measures the degree of correlation between the activities of different brain regions in the frequency domain. Phase synchronization [94] goes a step further, evaluating the temporal alignment of neural oscillations across different regions, which can reveal intricate patterns of neural communication pivotal for cognitive and motor functions.

D. Model Building

Many researchers have dedicated their efforts to translating human brain signals into text, exploring various innovative techniques. This field of study encompasses different methodologies for data collection, including EEG, fMRI, and ECoG. Each method offers unique insights and approaches to understanding brain activity. Deep neural networks, particularly RNNs [10], [112] and Long Short-Term Memory (LSTM) [113] networks, have demonstrated significant potential in decoding EEG signals into text. The BART [10] model is also emerging as a noteworthy tool in this domain. Bidirectional Auto-Regressive Transformers (BART), known for its effectiveness in various natural language processing tasks, is being adapted to interpret and convert EEG signals into coherent text. This adaptation signifies a promising convergence of advanced neural network architectures and neuroscientific data, potentially leading to more accurate and efficient EEGto-text conversion methodologies. In this article, the primary emphasis is on those papers that utilize EEG signals to generate text. This approach presents a fascinating challenge and holds significant potential for advancements in neuroscientific research and assistive technologies.

1) DeWave [112] : DeWave is a novel end-to-end model for EEG-to-text translation using discrete codex encoding. It uses self-supervised learning and contrastive learning to establish the link between brain activity and language. DeWave eliminates the need for pre-processing steps like feature extraction, potentially simplifying the overall decoding process. Figure 3 describes the architecture of the DeWave model.

Key steps in DeWave:

Discrete Codex Encoding: DeWave utilizes a technique called discrete codex encoding. This involves learning a codebook that maps continuous EEG signals into discrete code tokens. Imagine this codebook as a dictionary, where specific patterns in the EEG signal map to specific words or phrases.

Self-supervised Wave Encoding: The model learns this codebook through a self-supervised learning process. It essentially analyzes vast amounts of unlabeled EEG data and the corresponding text, allowing the model to discover the inherent relationships between brain activity and language.

Contrastive Learning for Alignment: DeWave employs contrastive learning to refine the alignment between the encoded EEG representations and the corresponding text. This process helps the model identify the most relevant EEG patterns that accurately reflect the intended text.

Text Generation: Finally, the model utilizes a decoder, often a Transformer-based architecture, which takes the encoded EEG representations (discrete code tokens) and translates them into the final text output, sentence by sentence.

- 2) MDADenseNet-AM [114] : The MDADenseNet-AM model is a complex and sophisticated deep learning architecture designed for converting EEG signals into text. Here's a breakdown of its mathematical and operational structure:

DenseNet Mechanism: The model uses the DenseNet mechanism, where the output from the m th convolutional layer (denoted as xd m ) is determined by the application of 3×3 convolution filters wd m d on the outputs of all preceding layers. The mathematical representation of this output is given by:

<!-- formula-not-decoded -->

Multiscale Dilated Convolution: To address issues like aliasing, the model incorporates a multiscale dilated convolution operation. This operation allows the network to have a variable and adjustable receptive field, enabling it to capture information at different scales and contexts. The multiscale dilated convolution is characterized by different dilation factors, which determine the spacing of the convolution kernel elements and influence the channel obtained in the network.

Integration with Attention Mechanism: The attention mechanism is integrated into the MDADenseNet to focus on the most relevant information and suppress less important details. This is achieved by performing a weighted summation over the hidden layers of the network. Mathematically, for feature vectors hh v , the environment vector cc v is calculated as follows:

<!-- formula-not-decoded -->

Figure 3: DeWave: A Transformer-Based EEG-to-Text Conversion Model.

Here, aa v represents the weights combined with the hidden state, indicating the importance of each feature in the context of the task.

Parameter Optimization with EOWGMO: The model is developed with an adaptive strategy for parameter optimization using the Eurasian Oystercatcher Wild Geese Migration Optimization (EOWGMO) algorithm. This approach optimizes parameters like optimizers and epochs in the DenseNet to enhance the accuracy and precision of the text conversion model. The optimization function can be represented as:

from previous time steps, capturing long-range dependencies between brain activity and intended meaning. Through a combination of "gates" that control information flow, the LSTM network analyzes current EEG features alongside previously predicted words, building the sentence word by word while considering the context of the entire sequence. This enables EEG-To-Text to decode diverse vocabulary and potentially capture the nuances of human thought.

<!-- formula-not-decoded -->

In this equation, OpDnt rr and EpDnt qr likely represent the ranges for the optimizer and epochs, respectively, while Ac and Pn are the accuracy and precision of the model.

3) EEG-to-Text [10] : This model, named EEG-To-Text, proposes a novel approach for open-vocabulary EEG-to-text decoding. It utilizes a combination of CNNs for feature extraction and LSTMs for sequence-to-sequence decoding. The model aims to overcome the limitations of pre-defined vocabularies and enable expressing a wider range of thoughts. The total working flow of the EEG-to-Text conversation model is shown in figure 4.

In the decoding stage of EEG-To-Text, LSTM networks play a crucial role in translating extracted EEG features into natural language sentences. Unlike traditional models, LSTMs excel at handling sequential data like EEG signals. Their internal memory mechanism allows them to retain information

4) J-CRNN-BCI [113] : This paper proposed a deep learning framework for brain-computer interface (BCI) typing. This framework utilizes a joint convolutional recurrent neural network (J-CRNN) to decode motor imagery EEG (MI-EEG) signals, translating imagined typing movements into actual text output.

Convolutional Neural Network (CNN): The first stage of the J-CRNN acts as a feature extractor. It processes the raw EEG data, which captures electrical activity across the brain, and identifies spatiotemporal patterns related to specific imagined movements. By applying filters and performing convolutions, the CNN extracts relevant features that differentiate between different typing intentions.

Recurrent Neural Network (RNN): The second stage of the J-CRNN captures the sequential nature of the EEG signals. Unlike the CNN, which analyzes individual data points, the RNN considers the temporal dependencies between these points. This allows the model to understand the evolving patterns within the EEG signal over time, which is crucial for distinguishing between the unique sequences associated with each imagined letter.

By combining the strengths of CNNs and RNNs in the J-

Figure 4: Integrative Framework for EEG Signal Decoding and Sentiment Analysis: Leveraging Pretrained Language Models for Text Generation and Emotion Classification.

CRNN architecture, the model effectively extracts informative features from the EEG data while simultaneously capturing the temporal dynamics of brain activity.

IV. FUTURE RESEARCH DIRECTION

A. Decoding complex thoughts and emotions

The recent advancements in EEG-to-text conversion are a significant achievement in neuroscientific research, offering new opportunities for communication, especially for those with speech and movement limitations. However, a notable gap in this domain is the current inability to accurately interpret and convey emotions through EEG signals. While researchers [10], [112] have developed models capable of translating brain activity into text, these models predominantly concentrate on the literal content and fail to consider the emotional context. This limitation underscores the complexity of human emotions and their representation in brain activity, which existing technologies have not fully captured. It requires a deeper understanding of the neural correlates of emotions and the development of more sophisticated algorithms to address these challenges. Enhancing the emotional sensitivity of EEG-totext systems will improve the fidelity of communication for users and has implications for fields like mental health. In this context, recognizing emotions can facilitate accurate diagnosis and effective therapy. Therefore, the next research phase in this domain focuses on integrating emotional intelligence into EEG-to-text systems, which will bridge the gap between technological capability and the nuanced spectrum of human expression.

B. Data Source Diversification

The advancement of research in EEG-to-text generation is contingent upon the diversification of data sources, a crucial step towards enhancing the accuracy and applicability of these systems. Currently, EEG datasets used in research are often limited in size and diversity, leading to models that may exhibit poor generalizability across diverse populations or settings. To address this, it is important to integrate a broader array of data sources, encompassing datasets from diverse demographics, emotional states, and environmental situations. Diversifying data sources improves the robustness of EEG-to-text models and ensures their inclusivity and adaptability in real-world scenarios. This approach aligns with the growing AI and machine learning trend towards creating more equitable and universally applicable technologies. Future research will likely focus on establishing large, varied datasets and developing models that can effectively learn from such complexity. This will facilitate the creation of EEG-to-text systems that are precise, dependable, and reflective of the wide-ranging human encounter.

C. Improving Accuracy and Reducing Errors

An important area of future research in EEG-to-text generation lies in enhancing accuracy and minimizing errors. This can be tackled through advancements in two key areas: deep learning architectures and signal processing techniques. On the one hand, novel deep learning models specifically designed to handle the inherent noise present in EEG data can be explored. These models could use techniques like residual connections or attention mechanisms to extract more robust features and reduce the impact of noise on text generation. On the other hand, developing advanced filtering and artifact removal methods can significantly improve the quality of EEG signals before they are fed into the text generation model. By integrating these approaches, researchers can significantly reduce errors and pave the way for more reliable and accurate communication through EEG-based text generation.

D. Developed a Multi-model

Future EEG-to-text generation advancements can extend beyond textual outputs. Although present research mostly concentrates on utilizing EEG for precise text generation, there is potential for a broader exploration of multimodality. This might involve using a single EEG signal to generate text and create complementary representations of the user's intent. However, it's important to distinguish this from directly generating images or voices from the EEG data. Instead, the focus would be on translating brain activity into additional modalities like simplified auditory representations of speech or basic visual icons that complement the textual output. This would require significant breakthroughs in deciphering the complex neural correlates not just of language processing but also of sensory information processing within the brain. Overall, multimodal EEG-to-text generation presents a fascinating future direction, offering the potential for a richer and more nuanced communication experience.

E. Cross-Domain Application

The expansion of EEG-to-text generation research into cross-domain applications represents a significant future direction, highlighting its potential beyond traditional boundaries. This approach involves applying EEG-to-text technologies across diverse domains such as healthcare, neuromarketing, and even the realm of creative arts, transcending its initial scope of aiding communication for those with disabilities. In healthcare, EEG-to-text systems could revolutionize patient care by providing non-verbal patients with a means to communicate their needs and symptoms. Moreover, in creative arts, this technology could offer a new medium for artists to translate their thoughts directly into textual form, pushing the boundaries of artistic expression. These cross-domain applications broaden the impact of EEG-to-text systems and encourage interdisciplinary collaboration, driving innovation and enhancing the depth of research in this field. To achieve successful cross-domain applications, it is important to modify the technology to align with the distinct demands and intricacies of each discipline. This task necessitates ongoing improvement and advancement of EEG-to-text systems.

V. CONCLUSION

The study of EEG-to-text translation represents a cuttingedge field in neuroscience and assistive technology that has demonstrated significant advancements in recent years. The progress in machine learning, namely in deep learning structures like RNNs, LSTMs, and transformer models, has established the foundation for advanced EEG decoding. DeWave and similar innovations provide a glimpse of the possibility of creating more direct and efficient communication pathways for individuals with speech or physical difficulties. The noninvasive nature of EEG makes it a prospective option for widescale application, given its potential to provide a means of communication for individuals who are unable to speak or write traditionally.

Future research directions indicate the need to incorporate emotional intelligence into EEG-to-text systems, broaden the range of data sources, and improve the precision and fluency of these models. The potential to use this technology in multimodal communication and other fields indicates a significant impact that may exceed its existing limitations. This extension into cross-domain applications demonstrates the versatility of EEG-to-text systems and their capacity to enhance different facets of human existence, from healthcare to creative expression.

REFERENCES

- [1] F. R. Willett, D. T. Avansino, L. R. Hochberg, J. M. Henderson, and K. V. Shenoy, 'High-performance brain-to-text communication via handwriting,' Nature , vol. 593, no. 7858, pp. 249-254, 2021.
- [2] F. Lotte, M. Congedo, A. Lécuyer, F. Lamarche, and B. Arnaldi, 'A review of classification algorithms for eeg-based brain-computer interfaces,' Journal of neural engineering , vol. 4, no. 2, p. R1, 2007.
- [3] C. Guger, N. F. Ince, M. Korostenskaja, and B. Z. Allison, 'Braincomputer interface research: A state-of-the-art summary 11,' in Brain-Computer Interface Research: A State-of-the-Art Summary 11 . Springer, 2024, pp. 1-11.
- [4] C. Chatelle, S. Laureys et al. , Assessing Pain and Communication in Disorders of consciousness . Psychology Press, 2016.
- [5] M. M. Rahman, A. K. Sarkar, M. A. Hossain, M. S. Hossain, M. R. Islam, M. B. Hossain, J. M. Quinn, and M. A. Moni, 'Recognition of human emotions using eeg signals: A review,' Computers in Biology and Medicine , vol. 136, p. 104696, 2021.
- [6] C. Yu and M. Wang, 'Survey of emotion recognition methods using eeg information,' Cognitive Robotics , vol. 2, pp. 132-146, 2022.
- [7] M. Ouchani, S. Gharibzadeh, M. Jamshidi, and M. Amini, 'A review of methods of diagnosis and complexity analysis of alzheimer's disease using eeg signals,' BioMed Research International , vol. 2021, pp. 115, 2021.
- [8] A. Chaddad, Y. Wu, R. Kateb, and A. Bouridane, 'Electroencephalography signal processing: A comprehensive review and analysis of methods and techniques,' Sensors , vol. 23, no. 14, p. 6434, 2023.
- [9] W. O. Tatum, B. A. Dworetzky, and D. L. Schomer, 'Artifact and recording concepts in eeg,' Journal of clinical neurophysiology , vol. 28, no. 3, pp. 252-263, 2011.
- [10] Z. Wang and H. Ji, 'Open vocabulary electroencephalography-to-text decoding and zero-shot sentiment classification,' in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 36, no. 5, 2022, pp. 5350-5358.
- [11] M. Trigka, E. Dritsas, and C. Fidas, 'A survey on signal processing methods for eeg-based brain computer interface systems,' in Proceedings of the 26th Pan-Hellenic Conference on Informatics , 2022, pp. 213-218.
- [12] M. Rashid, N. Sulaiman, A. PP Abdul Majeed, R. M. Musa, A. F. Ab Nasir, B. S. Bari, and S. Khatun, 'Current status, challenges, and possible solutions of eeg-based brain-computer interface: a comprehensive review,' Frontiers in neurorobotics , p. 25, 2020.
- [13] M. Orban, M. Elsamanty, K. Guo, S. Zhang, and H. Yang, 'A review of brain activity and eeg-based brain-computer interfaces for rehabilitation application,' Bioengineering , vol. 9, no. 12, p. 768, 2022.
- [14] X. Xu, M. Lin, and T. Xu, 'Epilepsy seizures prediction based on nonlinear features of eeg signal and gradient boosting decision tree,' International Journal of Environmental Research and Public Health , vol. 19, no. 18, p. 11326, 2022.
- [15] L. Hu and Z. Zhang, 'Eeg signal processing and feature extraction,' 2019.
- [16] B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K.-R. Muller, 'Optimizing spatial filters for robust eeg single-trial analysis,' IEEE Signal processing magazine , vol. 25, no. 1, pp. 41-56, 2007.
- [17] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo, A. Rakotomamonjy, and F. Yger, 'A review of classification algorithms for eeg-based brain-computer interfaces: a 10 year update,' Journal of neural engineering , vol. 15, no. 3, p. 031005, 2018.
- [18] J. Van Erp, F. Lotte, and M. Tangermann, 'Brain-computer interfaces: beyond medical applications,' Computer , vol. 45, no. 4, pp. 26-34, 2012.
- [19] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo, A. Rakotomamonjy, and F. Yger, 'A review of classification algorithms for eeg-based brain-computer interfaces: a 10 year update,' Journal of neural engineering , vol. 15, no. 3, p. 031005, 2018.

- [20] K. G. Hartmann, R. T. Schirrmeister, and T. Ball, 'Eeg-gan: Generative adversarial networks for electroencephalograhic (eeg) brain signals,' arXiv preprint arXiv:1806.01875 , 2018.
- [21] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, M. Glasstetter, K. Eggensperger, M. Tangermann, F. Hutter, W. Burgard, and T. Ball, 'Deep learning with convolutional neural networks for eeg decoding and visualization,' Human brain mapping , vol. 38, no. 11, pp. 53915420, 2017.
- [22] J. Van Erp, F. Lotte, and M. Tangermann, 'Brain-computer interfaces: beyond medical applications,' Computer , vol. 45, no. 4, pp. 26-34, 2012.
- [23] U. Chaudhary, N. Birbaumer, and A. Ramos-Murguialday, 'Braincomputer interfaces for communication and rehabilitation,' Nature Reviews Neurology , vol. 12, no. 9, pp. 513-525, 2016.
- [24] M. A. Lopez-Gordo, D. Sanchez-Morillo, and F. P. Valle, 'Dry eeg electrodes,' Sensors , vol. 14, no. 7, pp. 12 847-12 870, 2014.
- [25] J. Minguillon, M. A. Lopez-Gordo, and F. Pelayo, 'Trends in eeg-bci for daily-life: Requirements for artifact removal,' Biomedical Signal Processing and Control , vol. 31, pp. 407-418, 2017.
- [26] J. Van Erp, F. Lotte, and M. Tangermann, 'Brain-computer interfaces: beyond medical applications,' Computer , vol. 45, no. 4, pp. 26-34, 2012.
- [27] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo, A. Rakotomamonjy, and F. Yger, 'A review of classification algorithms for eeg-based brain-computer interfaces: a 10 year update,' Journal of neural engineering , vol. 15, no. 3, p. 031005, 2018.
- [28] C. Vidaurre and B. Blankertz, 'Towards a cure for bci illiteracy,' Brain topography , vol. 23, pp. 194-198, 2010.
- [29] V. Jayaram, M. Alamgir, Y. Altun, B. Scholkopf, and M. GrosseWentrup, 'Transfer learning in brain-computer interfaces,' IEEE Computational Intelligence Magazine , vol. 11, no. 1, pp. 20-31, 2016.
- [30] S. Makeig, M. Westerfield, T.-P. Jung, S. Enghoff, J. Townsend, E. Courchesne, and T. J. Sejnowski, 'Dynamic brain sources of visual evoked responses,' Science , vol. 295, no. 5555, pp. 690-694, 2002.
- [31] D. J. Krusienski, M. Grosse-Wentrup, F. Galán, D. Coyle, K. J. Miller, E. Forney, and C. W. Anderson, 'Critical issues in state-ofthe-art brain-computer interface signal processing,' Journal of neural engineering , vol. 8, no. 2, p. 025002, 2011.
- [32] J. Mak, Y. Arbel, J. W. Minett, L. M. McCane, B. Yuksel, D. Ryan, D. Thompson, L. Bianchi, and D. Erdogmus, 'Optimizing the p300based brain-computer interface: current status, limitations and future directions,' Journal of neural engineering , vol. 8, no. 2, p. 025003, 2011.
- [33] G. Mecacci and P. Haselager, 'Identifying criteria for the evaluation of the implications of brain reading for mental privacy,' Science and Engineering Ethics , vol. 25, pp. 443-461, 2019.
- [34] T. Bonaci, J. Herron, C. Matlack, and H. J. Chizeck, 'Securing the exocortex: A twenty-first century cybernetics challenge,' in 2014 IEEE conference on Norbert Wiener in the 21st century (21CW) . IEEE, 2014, pp. 1-8.
- [35] S. Wachter, B. Mittelstadt, and L. Floridi, 'Transparent, explainable, and accountable ai for robotics,' Science robotics , vol. 2, no. 6, p. eaan6080, 2017.
- [36] M. Ienca and R. Andorno, 'Towards new human rights in the age of neuroscience and neurotechnology,' Life sciences, society and policy , vol. 13, pp. 1-27, 2017.
- [37] P. Kellmeyer, T. Cochrane, O. Müller, C. Mitchell, T. Ball, J. J. Fins, and N. Biller-Andorno, 'The effects of closed-loop medical devices on the autonomy and accountability of persons and systems,' Cambridge Quarterly of Healthcare Ethics , vol. 25, no. 4, pp. 623-633, 2016.
- [38] S. Schicktanz, T. Amelung, and J. W. Rieger, 'Qualitative assessment of patients' attitudes and expectations toward bcis and implications for future technology development,' Frontiers in systems neuroscience , vol. 9, p. 64, 2015.
- [39] G. Wolbring, L. Diep, S. Yumakulov, N. Ball, and D. Yergens, 'Social robots, brain machine interfaces and neuro/cognitive enhancers: Three emerging science and technology products through the lens of technology acceptance theories, models and frameworks,' Technologies , vol. 1, no. 1, pp. 3-25, 2013.
- [40] N. Hollenstein, J. Rotsztejn, M. Troendle, A. Pedroni, C. Zhang, and N. Langer, 'Zuco, a simultaneous eeg and eye-tracking resource for natural sentence reading,' Scientific data , vol. 5, no. 1, pp. 1-13, 2018.
- [41] N. Hollenstein, M. Troendle, C. Zhang, and N. Langer, 'Zuco 2.0: A dataset of physiological recordings during natural reading and annotation,' arXiv preprint arXiv:1912.00903 , 2019.
- [42] F. Pereira, B. Lou, B. Pritchett, S. Ritter, S. J. Gershman, N. Kanwisher, M. Botvinick, and E. Fedorenko, 'Toward a universal decoder of
- linguistic meaning from brain activation,' Nature communications , vol. 9, no. 1, p. 963, 2018.
- [43] N. Affolter, B. Egressy, D. Pascual, and R. Wattenhofer, 'Brain2word: decoding brain activity for language generation,' arXiv preprint arXiv:2009.04765 , 2020.
- [44] C. Herff, D. Heger, A. De Pesters, D. Telaar, P. Brunner, G. Schalk, and T. Schultz, 'Brain-to-text: decoding spoken phrases from phone representations in the brain,' Frontiers in neuroscience , vol. 9, p. 217, 2015.
- [45] G. K. Anumanchipalli, J. Chartier, and E. F. Chang, 'Speech synthesis from neural decoding of spoken sentences,' Nature , vol. 568, no. 7753, pp. 493-498, 2019.
- [46] P. Wang, R. Zhou, S. Wang, L. Li, W. Bai, J. Fan, C. Li, P. Childs, and Y. Guo, 'A general framework for revealing human mind with auto-encoding gans,' arXiv preprint arXiv:2102.05236 , 2021.
- [47] P. Kumar, R. Saini, P. P. Roy, P. K. Sahu, and D. P. Dogra, 'Envisioned speech recognition using eeg sensors,' Personal and Ubiquitous Computing , vol. 22, pp. 185-199, 2018.
- [48] C. Spampinato, S. Palazzo, I. Kavasidis, D. Giordano, N. Souly, and M. Shah, 'Deep learning human mind for automated visual classification,' in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 6809-6817.
- [49] G. Shen, T. Horikawa, K. Majima, and Y. Kamitani, 'Deep image reconstruction from human brain activity,' PLoS computational biology , vol. 15, no. 1, p. e1006633, 2019.
- [50] K. N. Kay, T. Naselaris, R. J. Prenger, and J. L. Gallant, 'Identifying natural images from human brain activity,' Nature , vol. 452, no. 7185, pp. 352-355, 2008.
- [51] S. Lin, T. Sprague, and A. K. Singh, 'Mind reader: Reconstructing complex images from brain activities,' Advances in Neural Information Processing Systems , vol. 35, pp. 29 624-29 636, 2022.
- [52] 'Compumedics Neuroscan -World Leader in Functional Neuroimaging.' [Online]. Available: https://compumedicsneuroscan.com/
- [53] S. Sauer, 'Brain Products GmbH | Solutions for neurophysiological research.' [Online]. Available: https://www.brainproducts.com/
- [54] 'Biosemi EEG ECG EMG BSPM NEURO amplifier electrodes.' [Online]. Available: https://www.biosemi.com/
- [55] 'Homepage.' [Online]. Available: https://www.emotiv.com/
- [56] 'EEG - ECG - Biosensors.' [Online]. Available: https://neurosky.com/
- [57] 'ANT Neuro | inspiring technology for the human brain.' [Online]. Available: https://www.ant-neuro.com/
- [58] 'Advanced Brain Monitoring.' [Online]. Available: https://www. advancedbrainmonitoring.com/
- [59] 'OpenBCI Featured Products.' [Online]. Available: https://shop. openbci.com/collections/frontpage
- [60] G. Di Flumeri, P. Aricò, G. Borghini, A. Colosimo, and F. Babiloni, 'A new regression-based method for the eye blinks artifacts correction in the eeg signal, without using any eog channel,' in 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) . IEEE, 2016, pp. 3187-3190.
- [61] N. Ille, Y. Nakao, Y. Shumpei, T. Taura, A. Ebert, H. Bornfleth, S. Asagi, K. Kozawa, I. Itabashi, T. Sato et al. , 'Ongoing eeg artifact correction using blind source separation,' Clinical Neurophysiology , 2024.
- [62] M. Dora and D. Holcman, 'Adaptive single-channel eeg artifact removal with applications to clinical monitoring,' IEEE Transactions on Neural Systems and Rehabilitation Engineering , vol. 30, pp. 286-295, 2022.
- [63] M. K. Islam, P. Ghorbanzadeh, and A. Rastegarnia, 'Probability mapping based artifact detection and removal from single-channel eeg signals for brain-computer interface applications,' Journal of Neuroscience Methods , vol. 360, p. 109249, 2021.
- [64] Y. Dai, F. Duan, F. Feng, Z. Sun, Y. Zhang, C. F. Caiafa, P. MartiPuig, and J. Solé-Casals, 'A fast approach to removing muscle artifacts for eeg with signal serialization based ensemble empirical mode decomposition,' Entropy , vol. 23, no. 9, p. 1170, 2021.
- [65] C. Dora and P. K. Biswal, 'An improved algorithm for efficient ocular artifact suppression from frontal eeg electrodes using vmd,' Biocybernetics and Biomedical Engineering , vol. 40, no. 1, pp. 148161, 2020.
- [66] H. Massar, M. Miyara, T. Belhoussine Drissi, and B. Nsiri, 'An integrated approach for artifact elimination in eeg signals: Combining variational mode decomposition with blind source separation (vmdbss),' in The International Conference on Artificial Intelligence and Smart Environment . Springer, 2023, pp. 84-90.

- [67] L. Shoker, S. Sanei, and J. Chambers, 'Artifact removal from electroencephalograms using a hybrid bss-svm algorithm,' IEEE Signal Processing Letters , vol. 12, no. 10, pp. 721-724, 2005.
- [68] M. B. Hamaneh, N. Chitravas, K. Kaiboriboon, S. D. Lhatoo, and K. A. Loparo, 'Automated removal of ekg artifact from eeg data using independent component analysis and continuous wavelet transformation,' IEEE Transactions on Biomedical Engineering , vol. 61, no. 6, pp. 1634-1641, 2013.
- [69] M. A. Klados, C. Papadelis, C. Braun, and P. D. Bamidis, 'Reg-ica: a hybrid methodology combining blind source separation and regression techniques for the rejection of ocular artifacts,' Biomedical Signal Processing and Control , vol. 6, no. 3, pp. 291-300, 2011.
- [70] G. K. Soni, H. Singh, H. Arora, and A. Soni, 'Ultra low power cmos low pass filter for biomedical ecg/eeg application,' in 2020 Fourth International Conference on Inventive Systems and Control (ICISC) . IEEE, 2020, pp. 558-561.
- [71] I. Winkler, S. Debener, K.-R. Müller, and M. Tangermann, 'On the influence of high-pass filtering on ica-based artifact reduction in eegerp,' in 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) . IEEE, 2015, pp. 4101-4105.
- [72] J. Baranowski and P. Pi ˛tek, a 'Fractional band-pass filters: design, implementation and application to eeg signal processing,' Journal of Circuits, Systems and Computers , vol. 26, no. 11, p. 1750170, 2017.
- [73] W. Wang, G. Zhang, L. Yang, V. Balaji, V. Elamaran, and N. Arunkumar, 'Revisiting signal processing with spectrogram analysis on eeg, ecg and speech signals,' Future Generation Computer Systems , vol. 98, pp. 227-232, 2019.
- [74] S. Seifzadeh, K. Faez, and M. Amiri, 'Comparison of different linear filter design methods for handling ocular artifacts in brain computer interface system,' Journal of Computer &amp; Robotics , vol. 7, no. 1, pp. 51-56, 2014.
- [75] M. K. Ahirwal, A. Kumar, G. K. Singh, and N. D. Londhe, 'Performance prediction of adaptive filters for eeg signal,' IET Science, Measurement &amp; Technology , vol. 11, no. 5, pp. 525-531, 2017.
- [76] M. Z. Baig, Y. Mehmood, and Y. Ayaz, 'A bci system classification technique using median filtering and wavelet transform,' in Dynamics in Logistics: Proceedings of the 4th International Conference LDIC, 2014 Bremen, Germany . Springer, 2016, pp. 355-364.
- [77] T. A. Camilleri, K. P. Camilleri, and S. G. Fabri, 'Segmentation and labelling of eeg for brain computer interfaces,' in Computer Analysis of Images and Patterns: 16th International Conference, CAIP 2015, Valletta, Malta, September 2-4, 2015 Proceedings, Part I 16 . Springer, 2015, pp. 288-299.
- [78] P. C. Sharma, R. Raja, S. K. Vishwakarma, S. Sharma, P. K. Mishra, and V. S. Kushwah, 'Analysis of brain signal processing and real-time eeg signal enhancement,' Multimedia Tools and Applications , vol. 81, no. 28, pp. 41 013-41 033, 2022.
- [79] T. Parviainen and J. Kujala, 'Event-related potentials (erps) and eventrelated fields (erfs),' in Language Electrified: Principles, Methods, and Future Perspectives of Investigation . Springer, 2023, pp. 195-239.
- [80] Y. Tran, 'Eeg signal processing for biomedical applications,' p. 9754, 2022.
- [81] S. M. Qaisar, 'A computationally efficient eeg signals segmentation and de-noising based on an adaptive rate acquisition and processing,' in 2018 IEEE 3rd International Conference on Signal and Image Processing (ICSIP) . IEEE, 2018, pp. 182-186.
- [82] A. Rastogi and V. Bhateja, 'Pre-processing of electroencephalography signals using stationary wavelet transform-enhanced fixed-point fastica,' in Data Engineering and Intelligent Computing: Proceedings of ICICC 2020 . Springer, 2021, pp. 387-396.
- [83] C. M. Segning, J. Harvey, H. Ezzaidi, K. B. P. Fernandes, R. A. da Silva, and S. Ngomo, 'Towards the objective identification of the presence of pain based on electroencephalography signals' analysis: A proof-of-concept,' Sensors , vol. 22, no. 16, p. 6272, 2022.
- [84] R. Zhang, P. Xu, L. Guo, Y. Zhang, P. Li, and D. Yao, 'Z-score linear discriminant analysis for eeg based brain-computer interfaces,' PloS one , vol. 8, no. 9, p. e74433, 2013.
- [85] A. Apicella, F. Isgrò, A. Pollastro, and R. Prevete, 'On the effects of data normalization for domain adaptation on eeg data,' Engineering Applications of Artificial Intelligence , vol. 123, p. 106205, 2023.
- [86] Garima, N. Goel, and N. Rathee, 'Modified multidimensional scaling on eeg signals for emotion classification,' Multimedia Tools and Applications , pp. 1-22, 2023.
- [87] H. Zhang, Q.-Q. Zhou, H. Chen, X.-Q. Hu, W.-G. Li, Y. Bai, J.-X. Han, Y. Wang, Z.-H. Liang, D. Chen et al. , 'The applied principles of
- eeg analysis methods in neuroscience and clinical neurology,' Military Medical Research , vol. 10, no. 1, p. 67, 2023.
- [88] D. Hernández, L. Trujillo, E. Z-Flores, O. Villanueva, and O. RomoFewell, 'Detecting epilepsy in eeg signals using time, frequency and time-frequency domain features,' Computer science and engineering-theory and applications , pp. 167-182, 2018.
- [89] C. Wang, A. K. Verma, B. Guragain, X. Xiong, and C. Liu, 'Classification of bruxism based on time-frequency and nonlinear features of single channel eeg,' BMC Oral Health , vol. 24, no. 1, p. 81, 2024.
- [90] A. S. Al-Fahoum and A. A. Al-Fraihat, 'Methods of eeg signal features extraction using linear analysis in frequency and time-frequency domains,' International Scholarly Research Notices , vol. 2014, 2014.
- [91] T. Wen and Z. Zhang, 'Effective and extensible feature extraction method using genetic algorithm-based frequency-domain feature search for epileptic eeg multiclassification,' Medicine , vol. 96, no. 19, 2017.
- [92] H. Li, M. Liu, X. Yu, J. Zhu, C. Wang, X. Chen, C. Feng, J. Leng, Y. Zhang, and F. Xu, 'Coherence based graph convolution network for motor imagery-induced eeg after spinal cord injury,' Frontiers in Neuroscience , vol. 16, p. 1097660, 2023.
- [93] S. Chen, Z. Luo, and H. Gan, 'An entropy fusion method for feature extraction of eeg,' Neural Computing and Applications , vol. 29, pp. 857-863, 2018.
- [94] S. Ansarinasab, F. Ghassemi, Z. Tabanfar, and S. Jafari, 'Investigation of phase synchronization in functional brain networks of children with adhd using nonlinear recurrence measure,' Journal of Theoretical Biology , vol. 560, p. 111381, 2023.
- [95] K. Makkar and A. Bisen, 'Eeg signal processing and feature extraction,' International Journal for Modern Trends in Science and Technology , vol. 9, no. 08, pp. 45-50, 2023.
- [96] Q. Wei, Y. Wang, X. Gao, and S. Gao, 'Amplitude and phase coupling measures for feature extraction in an eeg-based brain-computer interface,' Journal of neural engineering , vol. 4, no. 2, p. 120, 2007.
- [97] M. N. Alam, M. I. Ibrahimy, and S. Motakabber, 'Feature extraction of eeg signal by power spectral density for motor imagery based bci,' in 2021 8th International Conference on Computer and Communication Engineering (ICCCE) . IEEE, 2021, pp. 234-237.
- [98] M. Singh and R. Goyat, 'Feature extraction for the analysis of multi-channel eeg signals using hilbert-huang technique,' International Journal of Engineering and Technology , vol. 8, no. 1, pp. 17-27, 2016.
- [99] A. S. Al-Fahoum and A. A. Al-Fraihat, 'Methods of eeg signal features extraction using linear analysis in frequency and time-frequency domains,' International Scholarly Research Notices , vol. 2014, 2014.
- [100] S.-H. Oh, Y.-R. Lee, and H.-N. Kim, 'A novel eeg feature extraction method using hjorth parameter,' International Journal of Electronics and Electrical Engineering , vol. 2, no. 2, pp. 106-110, 2014.
- [101] A. Patil, C. Deshmukh, and A. Panat, 'Feature extraction of eeg for emotion recognition using hjorth features and higher order crossings,' in 2016 Conference on Advances in Signal Processing (CASP) . IEEE, 2016, pp. 429-434.
- [102] L. I. Kuncheva and J. J. Rodríguez, 'Interval feature extraction for classification of event-related potentials (erp) in eeg data analysis,' Progress in Artificial Intelligence , vol. 2, pp. 65-72, 2013.
- [103] M. M. Ali, M. Taib, N. M. Tahir, and A. Jahidin, 'Eeg spectral centroid amplitude and band power features: A correlation analysis,' in 2014 IEEE 5th Control and System Graduate Research Colloquium . IEEE, 2014, pp. 223-226.
- [104] E. Wang, L. Wang, C. Ye, N. Luo, Y. Zhang, Y. Zhong, M. Zhu, Y. Zou, Q. Li, L. Li et al. , 'Effect of electroencephalography spectral edge frequency (sef) and patient state index (psi)-guided propofolremifentanil anesthesia on delirium after laparoscopic surgery: the emodipod randomized controlled trial,' Journal of Neurosurgical Anesthesiology , vol. 34, no. 2, pp. 183-192, 2022.
- [105] T.-j. Luo, 'Parallel genetic algorithm based common spatial patterns selection on time-frequency decomposed eeg signals for motor imagery brain-computer interface,' Biomedical Signal Processing and Control , vol. 80, p. 104397, 2023.
- [106] K. Saranya and M. Paulraj, 'Certain investigation on eeg signal processing using auto regression feature for various colour stimuli,' in 2023 International Conference on Intelligent Systems for Communication, IoT and Security (ICISCoIS) . IEEE, 2023, pp. 247-252.
- [107] J.-H. Kang, C. H. Lee, and S.-P. Kim, 'Eeg feature selection and the use of lyapunov exponents for eeg-based biometrics,' in 2016 IEEEEMBS International Conference on Biomedical and Health Informatics (BHI) . IEEE, 2016, pp. 228-231.
- [108] S. Geng, W. Zhou, Q. Yuan, D. Cai, and Y. Zeng, 'Eeg non-linear feature extraction using correlation dimension and hurst exponent,' Neurological research , vol. 33, no. 9, pp. 908-912, 2011.

[109] M. Aboy, R. Hornero, D. Abásolo, and D. Álvarez, 'Interpretation of the lempel-ziv complexity measure in the context of biomedical signal analysis,' IEEE transactions on biomedical engineering , vol. 53, no. 11, pp. 2282-2288, 2006.

[110] A. Goshvarpour, A. Abbasi, and A. Goshvarpour, 'Recurrence quantification analysis and neural networks for emotional eeg classification,' Applied Medical Informatics , vol. 38, no. 1, pp. 13-24, 2016.

[111] C. Guerrero-Mosquera, M. Verleysen, and A. N. Vazquez, 'Eeg feature selection using mutual information and support vector machine: A comparative analysis,' in 2010 Annual International Conference of the IEEE Engineering in Medicine and Biology . IEEE, 2010, pp. 49464949.

[112] Y. Duan, J. Zhou, Z. Wang, Y.-K. Wang, and C.-T. Lin, 'Dewave: Discrete eeg waves encoding for brain dynamics to text translation,' arXiv preprint arXiv:2309.14030 , 2023.

[113] X. Zhang, L. Yao, Q. Z. Sheng, S. S. Kanhere, T. Gu, and D. Zhang, 'Converting your thoughts to texts: Enabling brain typing via deep feature learning of eeg signals,' in 2018 IEEE international conference on pervasive computing and communications (PerCom) . IEEE, 2018, pp. 1-10.

[114] J. Yang, M. Awais, A. Hossain, L. Yee, M. Haowei, I. M. Mehedi, and A. Iskanderani, 'Thoughts of brain eeg signal-to-text conversion using weighted feature fusion-based multiscale dilated adaptive densenet with attention mechanism,' Biomedical Signal Processing and Control , vol. 86, p. 105120, 2023.