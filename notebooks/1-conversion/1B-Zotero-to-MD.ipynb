{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Zotero PDF to Markdown Converter\n",
    "\n",
    "This notebook connects to Zotero via its API, retrieves PDFs from a specific collection, extracts their content, and saves them as Markdown files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© How to Get Your Zotero API Key, User ID, and Collection Key\n",
    "\n",
    "To connect this notebook to your Zotero library, you'll need:\n",
    "\n",
    "1. A **Zotero API key**  \n",
    "2. Your **Zotero User ID**  \n",
    "3. The **Collection Key** for the folder containing your papers  \n",
    "\n",
    "---\n",
    "\n",
    "### üîë Step 1 ‚Äî Get Your Zotero API Key\n",
    "\n",
    "1. Go to: [https://www.zotero.org/settings/keys](https://www.zotero.org/settings/keys)\n",
    "2. Click **Create new private key**\n",
    "3. Give it a name like `Jupyter Notebook`\n",
    "4. Choose permission level: **Read Only**\n",
    "5. (Optional) Limit to a specific group or collection\n",
    "6. Click **Save Key**\n",
    "7. Copy your **API Key** and paste it into the notebook config\n",
    "\n",
    "---\n",
    "\n",
    "### üÜî Step 2 ‚Äî Find Your Zotero User ID\n",
    "\n",
    "1. Still at [https://www.zotero.org/settings/keys](https://www.zotero.org/settings/keys)\n",
    "2. Scroll down to the **Applications** section\n",
    "3. Your **User ID** is shown right below the blue button  \n",
    "   > Example: `Your user ID for use in API calls is 12345678`\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇÔ∏è Step 3 ‚Äî Find Your Collection Key\n",
    "\n",
    "1. Go to your **Zotero Web Library**: \n",
    "https://www.zotero.org/your_username/library\n",
    "\n",
    "2. Click on the desired collection (e.g. ‚ÄúCreativity in vitro‚Äù)\n",
    "3. Look at the browser URL ‚Äî it will look like this:\n",
    "\n",
    "https://www.zotero.org/your_username/collections/ABCD1234\n",
    "\n",
    "\n",
    "4. Copy the last part (`ABCD1234`) ‚Äî that is your **Collection Key**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "ZOTERO_USER_ID = \"13831668\"           # Replace with your Zotero user ID\n",
    "ZOTERO_API_KEY = \"1RZ3XyNVJkBEoTAJDhx5jwcb\"           # Replace with your Zotero API key\n",
    "COLLECTION_KEY = \"4Z2H2D4K\"     # Replace with the key of the desired collection\n",
    "ZOTERO_STORAGE_PATH = Path.home() / \"Zotero\" / \"storage\"  # Default Zotero local storage path\n",
    "HEADERS = {\"Zotero-API-Key\": ZOTERO_API_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß About the Functions Below\n",
    "\n",
    "The following functions are used to interact with the Zotero API and process the local PDFs:\n",
    "\n",
    "- **`get_items_from_collection(...)`**: Fetches all items (e.g., papers) from a specific Zotero collection using your User ID and Collection Key.\n",
    "- **`get_pdfs_for_item(...)`**: For each item (paper), this function retrieves all child attachments and filters only those with a PDF content type.\n",
    "- **`extract_text_from_pdf(...)`**: Reads the actual PDF file from local storage and extracts text from all pages using the PyPDF2 library.\n",
    "\n",
    "These functions together allow you to:\n",
    "1. Identify and locate the PDFs stored locally under Zotero's storage folder (named with unique keys like `2UH3FH6Z`).\n",
    "2. Extract the content of those PDFs and prepare them for further processing or conversion into Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_from_collection(user_id, collection_key):\n",
    "    url = f\"https://api.zotero.org/users/{user_id}/collections/{collection_key}/items?limit=100\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_pdfs_for_item(user_id, item_key):\n",
    "    url = f\"https://api.zotero.org/users/{user_id}/items/{item_key}/children\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "    return [att for att in response.json() if att[\"data\"].get(\"contentType\") == \"application/pdf\"]\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        return \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {pdf_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Mapping API Results to Local Zotero Storage\n",
    "\n",
    "This section connects the Zotero metadata (retrieved using the API) with the actual PDF files saved locally in Zotero's `storage` folder. Each PDF in Zotero is saved in a subfolder with a randomly generated name (like `2UH3FH6Z`), and the Zotero API provides the `key` that matches that folder name.\n",
    "\n",
    "Here's what happens:\n",
    "\n",
    "1. We call `get_items_from_collection(...)` to get all items from the specified collection.\n",
    "2. For each item (typically a paper), we call `get_pdfs_for_item(...)` to retrieve its child attachments and filter only the PDF files.\n",
    "3. For each PDF, we extract its `key` (which matches the local Zotero folder name).\n",
    "4. We check if that folder exists on disk and look for a `.pdf` file inside it.\n",
    "5. If a PDF is found, we save a `(title, path)` pair in the `pdf_map` list, which will be used later for conversion to Markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_map = []\n",
    "items = get_items_from_collection(ZOTERO_USER_ID, COLLECTION_KEY)\n",
    "\n",
    "for item in items:\n",
    "    title = item[\"data\"].get(\"title\", \"Untitled\")\n",
    "    item_key = item[\"data\"][\"key\"]\n",
    "    pdfs = get_pdfs_for_item(ZOTERO_USER_ID, item_key)\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        pdf_key = pdf[\"data\"][\"key\"]\n",
    "        folder_path = ZOTERO_STORAGE_PATH / pdf_key\n",
    "        if folder_path.exists():\n",
    "            pdf_files = list(folder_path.glob(\"*.pdf\"))\n",
    "            if pdf_files:\n",
    "                pdf_map.append((title, pdf_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brain decoding in multiple languages: Can cross-language brain decoding work?',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/2TSQFZCN/Xu et al. - 2021 - Brain decoding in multiple languages Can cross-language brain decoding work.pdf')),\n",
       " ('Thinking with images or thinking with language: a pilot EEG probability mapping study',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/R4VEIFZ5/Petsche et al. - 1992 - Thinking with images or thinking with language a pilot EEG probability mapping study.pdf')),\n",
       " ('Analysis of EEG Signals Related to Artists and Nonartists during Visual Perception, Mental Imagery, and Rest Using Approximate Entropy',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/5NQIFBDC/Shourie et al. - 2014 - Analysis of EEG Signals Related to Artists and Nonartists during Visual Perception, Mental Imagery,.pdf')),\n",
       " ('A neural speech decoding framework leveraging deep learning and speech synthesis',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/FW2MCAN8/Chen et al. - 2024 - A neural speech decoding framework leveraging deep learning and speech synthesis.pdf')),\n",
       " ('Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/QURA5E4Q/Moses et al. - 2021 - Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria.pdf')),\n",
       " ('Speech synthesis from neural decoding of spoken sentences',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/79Q4QD8Z/Anumanchipalli et al. - 2019 - Speech synthesis from neural decoding of spoken sentences.pdf')),\n",
       " ('Unveiling Thoughts: A Review of Advancements in EEG Brain Signal Decoding into Text',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/3E42WR9I/Murad and Rahimi - 2025 - Unveiling Thoughts A Review of Advancements in EEG Brain Signal Decoding into Text.pdf')),\n",
       " ('EEG-Based Classification of Spoken Words Using Machine Learning Approaches',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/CQLQPNSB/Alonso-V√°zquez et al. - 2023 - EEG-Based Classification of Spoken Words Using Machine Learning Approaches.pdf')),\n",
       " ('Semantic reconstruction of continuous language from non-invasive brain recordings',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/S23RCBM5/Tang et al. - 2023 - Semantic reconstruction of continuous language from non-invasive brain recordings.pdf')),\n",
       " ('Alignment of brain embeddings and artificial contextual embeddings in natural language points to common geometric patterns',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/YIJ63DMT/Goldstein et al. - 2024 - Alignment of brain embeddings and artificial contextual embeddings in natural language points to com.pdf')),\n",
       " ('Inducing brain-relevant bias in natural language processing models',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/TC4UK8TA/Schwartz et al. - 2019 - Inducing brain-relevant bias in natural language processing models.pdf')),\n",
       " ('Brains and algorithms partially converge in natural language processing',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/SPQGTBT6/Caucheteux and King - 2022 - Brains and algorithms partially converge in natural language processing.pdf')),\n",
       " ('Decoding EEG Brain Activity for Multi-Modal Natural Language Processing',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/M74PYKAU/Hollenstein et al. - 2021 - Decoding EEG Brain Activity for Multi-Modal Natural Language Processing.pdf')),\n",
       " ('Toward a universal decoder of linguistic meaning from brain activation',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/UMAN5I4J/Pereira et al. - 2018 - Toward a universal decoder of linguistic meaning from brain activation.pdf')),\n",
       " ('Reconstructing Speech from Human Auditory Cortex',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/PXB5AM88/Pasley et al. - 2012 - Reconstructing Speech from Human Auditory Cortex.pdf')),\n",
       " ('Predicting Human Brain Activity Associated with the Meanings of Nouns',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/F8MRI42C/Mitchell et al. - 2008 - Predicting Human Brain Activity Associated with the Meanings of Nouns.pdf')),\n",
       " ('Perceptogram: Reconstructing Visual Percepts from EEG',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/7PW2IPBR/Fei et al. - 2025 - Perceptogram Reconstructing Visual Percepts from EEG.pdf')),\n",
       " ('A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/MX7NEWN3/Shukla et al. - 2025 - A Survey on Bridging EEG Signals and Generative AI From Image and Text to Beyond.pdf')),\n",
       " ('Image classification and reconstruction from low-density EEG',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/HMHLE228/Guenther et al. - 2024 - Image classification and reconstruction from low-density EEG.pdf')),\n",
       " ('Improving classification and reconstruction of imagined images from EEG signals',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/2UH3FH6Z/Shimizu and Srinivasan - 2022 - Improving classification and reconstruction of imagined images from EEG signals.pdf')),\n",
       " ('Music can be reconstructed from human auditory cortex activity using nonlinear decoding models',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/B22ANWLX/Bellier et al. - 2023 - Music can be reconstructed from human auditory cortex activity using nonlinear decoding models.pdf')),\n",
       " ('DreamDiffusion: Generating High-Quality Images from Brain EEG Signals',\n",
       "  PosixPath('/Users/linalopes/Zotero/storage/VSYXC2R9/Bai et al. - 2023 - DreamDiffusion Generating High-Quality Images from Brain EEG Signals.pdf'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü™Ñ Convert PDF to Markdown with Docling (CLI Version)\n",
    "\n",
    "In this section, we use the [Docling CLI](https://github.com/doclinghq/docling) to convert each extracted PDF into Markdown format.\n",
    "\n",
    "The process involves calling `docling` from the command line using Python's `subprocess` module. The output is saved as a `.md` file in the `/markdown` folder at the root of this project.\n",
    "\n",
    "Make sure Docling is installed on your system and available in your terminal path. You can install it via pip if needed:\n",
    "\n",
    "```\n",
    "pip install docling\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"../../data/markdown\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for title, pdf_path in pdf_map:\n",
    "    print(f\"Converting with Docling: {pdf_path.name} ‚Üí markdown/\")\n",
    "\n",
    "    subprocess.run([\n",
    "        \"docling\",\n",
    "        str(pdf_path),\n",
    "        \"--output\",\n",
    "        str(output_dir)\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
